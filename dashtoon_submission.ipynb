{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18abff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.preprocessing import image as keras_image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b6cb19",
   "metadata": {},
   "source": [
    "    Load and preprocess an image from the given path.\n",
    "    Parameters:\n",
    "        image_path (str): Path to the image file.\n",
    "        target_size (tuple): Target size for resizing the image.\n",
    "    Returns:\n",
    "        np.array: Preprocessed image array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c233c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(image_path, target_size=(256, 256)):\n",
    "    img = keras_image.load_img(image_path, target_size=target_size)\n",
    "    img_array = keras_image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = keras.applications.vgg19.preprocess_input(img_array)\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74340f8",
   "metadata": {},
   "source": [
    "    Compute content loss between the content image and the generated image.\n",
    "    Parameters:\n",
    "        content (tf.Tensor): Feature representation of the content image.\n",
    "        combination (tf.Tensor): Feature representation of the generated image.\n",
    "    Returns:\n",
    "        tf.Tensor: Content loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8620a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute content loss\n",
    "def content_loss(content, combination):\n",
    "    return tf.reduce_sum(tf.square(combination - content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847eda7b",
   "metadata": {},
   "source": [
    "    Compute style loss between the style image and the generated image.\n",
    "    Parameters:\n",
    "        style (tf.Tensor): Feature representation of the style image.\n",
    "        combination (tf.Tensor): Feature representation of the generated image.\n",
    "    Returns:\n",
    "        tf.Tensor: Style loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute style loss\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = 256 * 256\n",
    "    return tf.reduce_sum(tf.square(S - C)) / (4.0 * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2aab4c",
   "metadata": {},
   "source": [
    "    Compute the Gram matrix for a given tensor.\n",
    "    Parameters:\n",
    "        x (tf.Tensor): Input tensor.\n",
    "    Returns:\n",
    "        tf.Tensor: Gram matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2bb112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute gram matrix\n",
    "def gram_matrix(x):\n",
    "    features = tf.keras.backend.batch_flatten(tf.keras.backend.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = tf.matmul(features, tf.transpose(features))\n",
    "    return gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d89db0",
   "metadata": {},
   "source": [
    "    Compute total variation loss to reduce noise in the generated image.\n",
    "    Parameters:\n",
    "        x (tf.Tensor): Input tensor.\n",
    "    Returns:\n",
    "        tf.Tensor: Total variation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffa3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute total variation loss (to reduce noise)\n",
    "def total_variation_loss(x):\n",
    "    a = tf.square(x[:, :255, :255, :] - x[:, 1:, :255, :])\n",
    "    b = tf.square(x[:, :255, :255, :] - x[:, :255, 1:, :])\n",
    "    return tf.reduce_sum(tf.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04f79cd",
   "metadata": {},
   "source": [
    "    Build the style transfer model using the VGG19 architecture.\n",
    "    Returns:\n",
    "        tf.keras.Model: Style transfer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5b1532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the style transfer model\n",
    "def build_style_transfer_model():\n",
    "    vgg19 = VGG19(weights='imagenet', include_top=False)\n",
    "\n",
    "    # Get intermediate layers for content and style representations\n",
    "    content_layers = ['block5_conv2']\n",
    "    style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
    "\n",
    "    content_outputs = [vgg19.get_layer(name).output for name in content_layers]\n",
    "    style_outputs = [vgg19.get_layer(name).output for name in style_layers]\n",
    "\n",
    "    model_outputs = content_outputs + style_outputs\n",
    "\n",
    "    # Build model\n",
    "    model = keras.models.Model(inputs=vgg19.input, outputs=model_outputs)\n",
    "    model.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7de1f4",
   "metadata": {},
   "source": [
    "    Compute the total style transfer loss.\n",
    "    Parameters:\n",
    "        content_image (tf.Tensor): Content image.\n",
    "        style_image (tf.Tensor): Style image.\n",
    "        generated_image (tf.Tensor): Generated image.\n",
    "        alpha (float): Weight for total variation loss.\n",
    "        beta (float): Weight for the total style transfer loss.\n",
    "    Returns:\n",
    "        tf.Tensor: Total style transfer loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caab74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute style transfer loss\n",
    "def style_transfer_loss(content_image, style_image, generated_image, alpha=1e4, beta=1e-4):\n",
    "    content_features = model(content_image)[:len(content_layers)]\n",
    "    style_features = model(style_image)[len(content_layers):]\n",
    "    generated_features = model(generated_image)\n",
    "\n",
    "    loss = 0.0\n",
    "\n",
    "    # Content loss\n",
    "    for content, generated in zip(content_features, generated_features[:len(content_layers)]):\n",
    "        loss += content_loss(content, generated)\n",
    "\n",
    "    # Style loss\n",
    "    for style, generated in zip(style_features, generated_features[len(content_layers):]):\n",
    "        loss += style_loss(style, generated)\n",
    "\n",
    "    # Total Variation loss (to reduce noise)\n",
    "    loss += alpha * tf.image.total_variation(generated_image)\n",
    "\n",
    "    return beta * loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c2980",
   "metadata": {},
   "source": [
    "    Download and load the WikiArt and MS COCO datasets using TensorFlow Datasets.\n",
    "    Returns:\n",
    "        tuple: A tuple containing content images and style images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download and load datasets\n",
    "def download_and_load_datasets():\n",
    "    # Download WikiArt dataset\n",
    "    wikiart_builder = tfds.builder('wikiart')\n",
    "    wikiart_builder.download_and_prepare()\n",
    "    wikiart = wikiart_builder.as_dataset(split='train[:10%]')  # Adjust the split as needed\n",
    "    wikiart_images = [img['image'] for img in tfds.as_numpy(wikiart)]\n",
    "\n",
    "    # Download MS COCO dataset\n",
    "    coco_builder = tfds.builder('coco/2017')\n",
    "    coco_builder.download_and_prepare()\n",
    "    coco = coco_builder.as_dataset(split='train[:10%]')  # Adjust the split as needed\n",
    "    coco_images = [img['image'] for img in tfds.as_numpy(coco)]\n",
    "    \n",
    "    return coco_images, wikiart_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e054ec",
   "metadata": {},
   "source": [
    "    Display content, style, and generated images side by side.\n",
    "    Parameters:\n",
    "        content (tf.Tensor): Content image.\n",
    "        style (tf.Tensor): Style image.\n",
    "        generated (tf.Tensor): Generated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f1314f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display images\n",
    "def display_images(content, style, generated):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(content[0]))\n",
    "    plt.title('Content Image')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(style[0]))\n",
    "    plt.title('Style Image')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(generated[0]))\n",
    "    plt.title('Generated Image')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c28ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "content_images, style_images = download_and_load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4756677e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split datasets\n",
    "train_content_images, val_content_images = train_test_split(content_images, test_size=0.2, random_state=42)\n",
    "train_style_images, val_style_images = train_test_split(style_images, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106af17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the style transfer model\n",
    "model = build_style_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a07d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the optimizer\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd775b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with visualization\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    # Iterate over batches\n",
    "    for i in range(0, len(train_content_images), batch_size):\n",
    "        batch_content = train_content_images[i:i + batch_size]\n",
    "        batch_style = train_style_images[i:i + batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = style_transfer_loss(batch_content, batch_style, model(batch_content))\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # Display visual examples during training\n",
    "        if i % 500 == 0:\n",
    "            display_images(batch_content, batch_style, model(batch_content))\n",
    "\n",
    "    # Validate the model on the validation set\n",
    "    val_loss = style_transfer_loss(val_content_images, val_style_images, model(val_content_images)).numpy()\n",
    "    print(f\"Validation Loss: {val_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d794cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('style_transfer_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f92632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load COCO 2017 test dataset for testing the model using the Tensorflow Dataset\n",
    "coco_test_builder = tfds.builder('coco/2017')\n",
    "coco_test_builder.download_and_prepare()\n",
    "coco_test = coco_test_builder.as_dataset(split='test')\n",
    "coco_test_images = [img['image'] for img in tfds.as_numpy(coco_test.take(1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b64899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take input for the test image path from the user\n",
    "test_image_path = input(\"Enter the path to the test image: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the user-provided test image\n",
    "test_image = load_and_preprocess_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4306ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize style transfer on the test image\n",
    "generated_image = model(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6686947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the test image and the generated image\n",
    "display_images(test_image, np.zeros_like(test_image), generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bd09e",
   "metadata": {},
   "source": [
    "    Limitations:\n",
    "        1) Single Style Transfer\n",
    "        2) Parameter Sensitivity\n",
    "        3) Limited Image Resolution\n",
    "        4) Content and Style Dimension Mismatch\n",
    "    Improvements:\n",
    "        1) Architectural Enhancements\n",
    "        2) Algorithmic Improvements\n",
    "        3) Using a Diverse Dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
